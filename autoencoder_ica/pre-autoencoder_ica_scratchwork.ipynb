{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BADLY NEEDS REFACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like I said at the end of my previous post, we might want to learn an invertible function more complicated than a linear map to obtain independent components of our data. Neural networks present a particularly appealing option for this due to their power as function approximators. We have two options here. One, we could learn some unmixing function using a network we very carefully design to be invertible, then very carefully construct the inverse. Alternatively, we can design an autoencoder to try to approximate the identity function and try to get one of the intermediate layers to develop independent features. This would give us the unmixing function (the composition of layers up to that point) as well as our mixing function (the layers from that point on to the end) whose composition is by construction (around) the identity map.\n",
    "\n",
    "Let's try the latter approach since it sounds more interesting. First, we have to convince ourselves that this is a reasonable thing to ask an autoencoder to do even in the simplest case. Thus, we'll first attempt to do linear ICA on the same data as before using this new approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our data, just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from typing import Tuple\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create convenience function for plotting and playing audio\n",
    "def show_audio(a: Tuple[int, np.ndarray])->None: # a: (sample_rate, audio_array)\n",
    "    fig, ax = plt.subplots()\n",
    "    time_axis = np.linspace(start=0, stop=(len(a[1])/a[0]),num=np.round(len(a[1])))\n",
    "    ax.plot(time_axis, a[1])\n",
    "    ax.set_xlabel('Time (seconds)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    display(Audio(a[1], rate=a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the wav files\n",
    "files = glob.glob('../ica/data/mixed_data/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_rates = []\n",
    "sound_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect sampling frequencies and audio signals\n",
    "for f in files:\n",
    "    samp_rate, sound = wavfile.read(f)\n",
    "    samp_rates.append(samp_rate)\n",
    "    sound_list.append(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as numpy array\n",
    "audio_array = np.array(sound_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# listen and visualize sound waves as sanity check\n",
    "for row in audio_array:\n",
    "    show_audio((samp_rate, row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing like the sound of mixed up audio clips in the morning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use PyTorch tensors so that later we can easily do gradient descent and other fun things\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as utils\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I want to prove to myself that I can code. If we make a complete autoencoder, it should surely be able to perfectly map the input to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our autoencoder architecture\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(4, 4, bias=False))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 4, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyperparameters\n",
    "num_epochs = 1\n",
    "batch_size = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-mean input\n",
    "X = audio_array\n",
    "n, p = X.shape\n",
    "n_components=min(n,p)\n",
    "X_mean = X.mean(axis=-1)\n",
    "X -= X_mean[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del audio_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whitening and preprocessing by PCA (i.e. SVD as our data is mean-centered)\n",
    "# taken from scikit-learn's source code\n",
    "u, d, _ = linalg.svd(X, full_matrices=False)\n",
    "\n",
    "del _\n",
    "K = (u / d).T[:n_components]\n",
    "del u, d\n",
    "X1 = K @ X\n",
    "# Here X1 is white and data\n",
    "# in X has been projected onto a subspace by PCA\n",
    "X1 *= np.sqrt(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.tensor(X1,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we permute the input data to better pretend each of our timestamps was drawn independently - helps with convergence\n",
    "X1 = X1[:,torch.randperm(X1.shape[1], dtype=torch.long)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataloader\n",
    "audio_dataset = utils.TensorDataset(X1.t())\n",
    "audio_dataloader = utils.DataLoader(audio_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for idx, x_t in enumerate(audio_dataloader):\n",
    "        x_t = x_t[0]\n",
    "        x_t = x_t.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(x_t)\n",
    "        loss = criterion(output, x_t)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(idx, loss.item())\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = model(torch.Tensor(np.matmul(K, X)).to(device).transpose(0,1)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test2 = (np.linalg.inv(K) @ test.T).T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for row in test2.T:\n",
    "    #print(test2.shape)\n",
    "    show_audio((samp_rate, row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shockingly enough (read: completely unsurprisingly), it seems we have learned the identity function perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate product of layer weights (composite transform) - check for identity\n",
    "composite = torch.eye(4, device=device)\n",
    "for layer_weights in model.parameters():\n",
    "    composite = torch.mm(composite, layer_weights)\n",
    "    \n",
    "print((torch.round(composite).cpu().detach().numpy() == np.eye(4)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our autoencoder architecture\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(4, 4, bias=False))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 4, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss parameter for encoder map to independent components\n",
    "coeff = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions\n",
    "def log_likelihood(s_pred: torch.Tensor, W: torch.Tensor)->torch.Tensor:\n",
    "    return torch.sum(torch.log(prob_s(s_pred))) + torch.log(torch.abs(torch.det(W)))\n",
    "\n",
    "def sigmoid_der(Y: torch.Tensor)->torch.Tensor:\n",
    "    a = torch.sigmoid(Y)\n",
    "    b = 1 - torch.sigmoid(Y)\n",
    "    return a*b\n",
    "def prob_s(s: torch.Tensor)->torch.Tensor:\n",
    "    return sigmoid_der(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.encoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t @ next(model.encoder.parameters()).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = torch.randn(1,4)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_2 = (next(model.encoder.parameters()) @ torch.tensor(K @ X, dtype=torch.float)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(S_2):\n",
    "    show_audio((samp_rate, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.encoder.parameters()).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model(torch.Tensor(np.matmul(K, X)).to(device).transpose(0,1)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = (np.linalg.inv(K) @ test.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test2.T:\n",
    "    #print(test2.shape)\n",
    "    show_audio((samp_rate, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liveloss = PlotLosses()\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, x_t in enumerate(audio_dataloader):\n",
    "        x_t = x_t[0]\n",
    "        x_t = x_t.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        output = model.encoder(x_t)\n",
    "        #mse = criterion(output, x_t)\n",
    "        ica_loss = -log_likelihood(output, next(model.encoder.parameters()))\n",
    "        loss = coeff*ica_loss #+ mse\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(idx, \n",
    "              #'MSE: ', mse.item(), \n",
    "              #' ICA NLLV: ', ica_loss.item(), \n",
    "              ' Total Loss: ', loss.item(), end='\\r')\n",
    "#     liveloss.update({\n",
    "#         #'MSE': mse.item(),\n",
    "#         #'ICA NLLV': ica_loss.item(), \n",
    "#         'Total Loss': loss.item()\n",
    "#     })\n",
    "#     liveloss.draw()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t @ next(model.encoder.parameters()).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.encoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model(torch.Tensor(np.matmul(K, X)).to(device).transpose(0,1)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = (np.linalg.inv(K) @ test.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test2.T:\n",
    "    #print(test2.shape)\n",
    "    show_audio((samp_rate, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate product of layer weights (composite transform) - check for identity\n",
    "composite = torch.eye(4, device=device)\n",
    "for layer_weights in model.parameters():\n",
    "    composite = torch.mm(composite, layer_weights)\n",
    "    \n",
    "print((torch.round(composite).cpu().detach().numpy() == np.eye(4)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.encoder(torch.Tensor(np.matmul(K, X)).to(device).transpose(0,1)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = (np.linalg.inv(K) @ test.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in test2.T:\n",
    "    show_audio((samp_rate, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
